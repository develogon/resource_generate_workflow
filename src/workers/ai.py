"""AIãƒ¯ãƒ¼ã‚«ãƒ¼."""

import logging
from typing import Set, Dict, Any, Optional
import asyncio
from dataclasses import dataclass

from .base import BaseWorker, Event, EventType
from ..config import Config

logger = logging.getLogger(__name__)


@dataclass
class GenerationRequest:
    """ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ."""
    content_type: str
    input_data: Dict[str, Any]
    context: Dict[str, Any]
    options: Dict[str, Any] = None


class AIWorker(BaseWorker):
    """AIå‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼."""
    
    def __init__(self, config: Config, worker_id: str = "ai_worker"):
        """åˆæœŸåŒ–."""
        super().__init__(config, worker_id)
        self.claude_client = None  # å¾Œã§å®Ÿè£…
        self.openai_client = None  # å¾Œã§å®Ÿè£…
        self.rate_limiter = None   # å¾Œã§å®Ÿè£…
        
    def get_subscriptions(self) -> Set[EventType]:
        """è³¼èª­ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’è¿”ã™."""
        return {
            EventType.SECTION_PARSED,
            EventType.PARAGRAPH_PARSED,
            EventType.CHAPTER_AGGREGATED,
            EventType.STRUCTURE_ANALYZED
        }
        
    async def process(self, event: Event) -> None:
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†."""
        try:
            if event.type == EventType.SECTION_PARSED:
                await self._handle_section_parsed(event)
            elif event.type == EventType.PARAGRAPH_PARSED:
                await self._handle_paragraph_parsed(event)
            elif event.type == EventType.CHAPTER_AGGREGATED:
                await self._handle_chapter_aggregated(event)
            elif event.type == EventType.STRUCTURE_ANALYZED:
                await self._handle_structure_analyzed(event)
            else:
                logger.warning(f"Unhandled event type: {event.type}")
                
        except Exception as e:
            logger.error(f"AI worker error: {e}")
            raise
            
    async def _handle_section_parsed(self, event: Event) -> None:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³è§£æã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†."""
        section_data = event.data.get('section')
        if not section_data:
            raise ValueError("No section data provided")
            
        logger.info(f"Analyzing structure for section: {section_data.get('title', 'Unknown')}")
        
        # æ§‹é€ è§£æã‚’å®Ÿè¡Œ
        analysis_result = await self._analyze_section_structure(section_data)
        
        # æ§‹é€ è§£æå®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
        if self.event_bus:
            analysis_event = Event(
                type=EventType.STRUCTURE_ANALYZED,
                workflow_id=event.workflow_id,
                data={
                    'section': section_data,
                    'analysis': analysis_result,
                    'chapter': event.data.get('chapter')
                },
                trace_id=event.trace_id
            )
            await self.event_bus.publish(analysis_event)
            
    async def _handle_paragraph_parsed(self, event: Event) -> None:
        """ãƒ‘ãƒ©ã‚°ãƒ©ãƒ•è§£æã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†."""
        # ãƒ‘ãƒ¼ã‚µãƒ¼ãƒ¯ãƒ¼ã‚«ãƒ¼ã‹ã‚‰ç›´æ¥é€ä¿¡ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¯¾å¿œ
        paragraph_data = event.data
        
        if not paragraph_data or not paragraph_data.get('content'):
            raise ValueError("No paragraph data provided")
            
        logger.info(f"Generating content for paragraph {paragraph_data.get('paragraph_index', 0)}")
        
        # ä¸¦åˆ—ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
        generation_tasks = [
            self._generate_article(paragraph_data, None),
            self._generate_script(paragraph_data, None),
            self._generate_script_json(paragraph_data, None),
            self._generate_tweet(paragraph_data, None),
            self._generate_description(paragraph_data, None)
        ]
        
        results = await asyncio.gather(*generation_tasks, return_exceptions=True)
        
        # æˆåŠŸã—ãŸçµæœã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ç™ºè¡Œ
        for idx, result in enumerate(results):
            if not isinstance(result, Exception) and result:
                content_event = Event(
                    type=EventType.CONTENT_GENERATED,
                    workflow_id=event.workflow_id,
                    data={
                        'content': result,
                        'paragraph': paragraph_data,
                        'section': None
                    },
                    trace_id=event.trace_id
                )
                if self.event_bus:
                    await self.event_bus.publish(content_event)
            elif isinstance(result, Exception):
                logger.error(f"Content generation failed for task {idx}: {result}")
                
    async def _handle_chapter_aggregated(self, event: Event) -> None:
        """ãƒãƒ£ãƒ—ã‚¿ãƒ¼é›†ç´„ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†."""
        chapter_data = event.data.get('chapter')
        if not chapter_data:
            raise ValueError("No chapter data provided")
            
        logger.info(f"Generating metadata for chapter: {chapter_data.get('title', 'Unknown')}")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        metadata = await self._generate_chapter_metadata(chapter_data)
        
        # ã‚µãƒ ãƒã‚¤ãƒ«ç”Ÿæˆ
        thumbnail_data = await self._generate_thumbnail(chapter_data)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºè¡Œ
        if self.event_bus:
            metadata_event = Event(
                type=EventType.METADATA_GENERATED,
                workflow_id=event.workflow_id,
                data={
                    'chapter': chapter_data,
                    'metadata': metadata,
                    'thumbnail': thumbnail_data
                },
                trace_id=event.trace_id
            )
            await self.event_bus.publish(metadata_event)
            
    async def _handle_structure_analyzed(self, event: Event) -> None:
        """æ§‹é€ è§£æã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†."""
        section_data = event.data.get('section')
        analysis_result = event.data.get('analysis')
        
        if not section_data or not analysis_result:
            logger.warning("Incomplete structure analysis data")
            return
            
        logger.info(f"Structure analysis completed for section: {section_data.get('title', 'Unknown')}")
        
        # å¿…è¦ã«å¿œã˜ã¦è¿½åŠ ã®å‡¦ç†ã‚’å®Ÿè¡Œ
        # ä¾‹: ç‰¹å®šã®æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãè¿½åŠ ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
        
    async def _analyze_section_structure(self, section_data: Dict[str, Any]) -> Dict[str, Any]:
        """ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æ§‹é€ ã‚’è§£æ."""
        # TODO: å®Ÿéš›ã®AI APIã‚’ä½¿ç”¨ã—ãŸæ§‹é€ è§£æ
        content = section_data.get('content', '')
        paragraphs = section_data.get('paragraphs', [])
        
        # åŸºæœ¬çš„ãªæ§‹é€ è§£æï¼ˆå®Ÿè£…ä¾‹ï¼‰
        analysis = {
            'content_type': self._classify_content_type(content),
            'complexity_level': self._assess_complexity(content),
            'key_concepts': self._extract_key_concepts(content),
            'paragraph_count': len(paragraphs),
            'estimated_reading_time': self._estimate_reading_time(content),
            'recommended_formats': self._recommend_formats(content)
        }
        
        return analysis
        
    async def _generate_article(self, paragraph_data: Dict[str, Any], section_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ."""
        try:
            # TODO: å®Ÿéš›ã®AI APIã‚’ä½¿ç”¨ã—ãŸè¨˜äº‹ç”Ÿæˆ
            content = paragraph_data.get('content', '')
            section_title = section_data.get('title', '') if section_data else paragraph_data.get('title', 'Unknown')
            
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: å®Ÿéš›ã®å®Ÿè£…ã§ã¯ Claude/OpenAI API ã‚’ä½¿ç”¨
            generated_article = {
                'type': 'article',
                'title': f"è¨˜äº‹: {section_title}",
                'content': f"ã€è¨˜äº‹ã€‘{content}\n\nã“ã®å†…å®¹ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™...",
                'word_count': len(content.split()) * 3,  # æ‹¡å¼µã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å˜èªæ•°
                'format': 'markdown'
            }
            
            await asyncio.sleep(0.1)  # APIå‘¼ã³å‡ºã—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            return generated_article
            
        except Exception as e:
            logger.error(f"Article generation failed: {e}")
            return None
            
    async def _generate_script(self, paragraph_data: Dict[str, Any], section_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å‹•ç”»å°æœ¬ã‚’ç”Ÿæˆ."""
        try:
            content = paragraph_data.get('content', '')
            section_title = section_data.get('title', '') if section_data else paragraph_data.get('title', 'Unknown')
            
            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: å®Ÿéš›ã®å®Ÿè£…ã§ã¯ AI API ã‚’ä½¿ç”¨
            generated_script = {
                'type': 'script',
                'title': f"å°æœ¬: {section_title}",
                'content': f"ã€å°æœ¬ã€‘\nãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {content}\n\nï¼ˆç”»é¢è¡¨ç¤º: é–¢é€£å›³è¡¨ï¼‰\n\nã“ã®ã‚ˆã†ã«ã€{content}ã«ã¤ã„ã¦èª¬æ˜ã§ãã¾ã™ã€‚",
                'duration_seconds': len(content.split()) * 2,  # æ¨å®šæ™‚é–“
                'format': 'text'
            }
            
            await asyncio.sleep(0.1)
            return generated_script
            
        except Exception as e:
            logger.error(f"Script generation failed: {e}")
            return None
            
    async def _generate_script_json(self, paragraph_data: Dict[str, Any], section_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ§‹é€ åŒ–ã•ã‚ŒãŸå‹•ç”»å°æœ¬ï¼ˆJSONå½¢å¼ï¼‰ã‚’ç”Ÿæˆ."""
        try:
            content = paragraph_data.get('content', '')
            section_title = section_data.get('title', '') if section_data else paragraph_data.get('title', 'Unknown')
            
            # æ§‹é€ åŒ–ã•ã‚ŒãŸå°æœ¬ãƒ‡ãƒ¼ã‚¿
            script_structure = {
                'type': 'script_json',
                'title': f"æ§‹é€ åŒ–å°æœ¬: {section_title}",
                'scenes': [
                    {
                        'scene_id': 1,
                        'type': 'introduction',
                        'narration': f"ä»Šå›ã¯{section_title}ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚",
                        'visual_elements': ['title_slide'],
                        'duration': 3
                    },
                    {
                        'scene_id': 2,
                        'type': 'main_content',
                        'narration': content,
                        'visual_elements': ['code_example', 'diagram'],
                        'duration': len(content.split()) * 1.5
                    },
                    {
                        'scene_id': 3,
                        'type': 'summary',
                        'narration': f"{section_title}ã®ãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ã‚‹ã¨...",
                        'visual_elements': ['summary_slide'],
                        'duration': 2
                    }
                ],
                'total_duration': len(content.split()) * 1.5 + 5,
                'format': 'json'
            }
            
            await asyncio.sleep(0.1)
            return script_structure
            
        except Exception as e:
            logger.error(f"Structured script generation failed: {e}")
            return None
            
    async def _generate_tweet(self, paragraph_data: Dict[str, Any], section_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ãƒ„ã‚¤ãƒ¼ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ."""
        try:
            content = paragraph_data.get('content', '')
            section_title = section_data.get('title', '') if section_data else paragraph_data.get('title', 'Unknown')
            
            # 140æ–‡å­—ä»¥å†…ã®ãƒ„ã‚¤ãƒ¼ãƒˆç”Ÿæˆ
            tweet_content = content[:100] + "..." if len(content) > 100 else content
            
            generated_tweet = {
                'type': 'tweet',
                'title': f"ãƒ„ã‚¤ãƒ¼ãƒˆ: {section_title}",
                'content': f"ğŸš€ {section_title}\n\n{tweet_content}\n\n#ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° #æŠ€è¡“è§£èª¬",
                'character_count': len(f"ğŸš€ {section_title}\n\n{tweet_content}\n\n#ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° #æŠ€è¡“è§£èª¬"),
                'hashtags': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'æŠ€è¡“è§£èª¬'],
                'format': 'text'
            }
            
            await asyncio.sleep(0.1)
            return generated_tweet
            
        except Exception as e:
            logger.error(f"Tweet generation failed: {e}")
            return None
            
    async def _generate_description(self, paragraph_data: Dict[str, Any], section_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """èª¬æ˜æ–‡ã‚’ç”Ÿæˆ."""
        try:
            content = paragraph_data.get('content', '')
            section_title = section_data.get('title', '') if section_data else paragraph_data.get('title', 'Unknown')
            
            # èª¬æ˜æ–‡ç”Ÿæˆ
            generated_description = {
                'type': 'description',
                'title': f"èª¬æ˜: {section_title}",
                'content': f"{section_title}ã«ã¤ã„ã¦ï¼š\n\n{content}\n\nã“ã®æŠ€è¡“ã¯ç¾ä»£ã®é–‹ç™ºã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚",
                'word_count': len(content.split()) + 20,
                'format': 'text'
            }
            
            await asyncio.sleep(0.1)
            return generated_description
            
        except Exception as e:
            logger.error(f"Description generation failed: {e}")
            return None
            
    async def _generate_chapter_metadata(self, chapter_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ."""
        try:
            title = chapter_data.get('title', '')
            sections = chapter_data.get('sections', [])
            
            # åŸºæœ¬çš„ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            metadata = {
                'title': title,
                'section_count': len(sections),
                'total_paragraphs': sum(len(section.get('paragraphs', [])) for section in sections),
                'estimated_reading_time': self._estimate_reading_time(chapter_data.get('content', '')),
                'difficulty_level': 'intermediate',  # TODO: AIåˆ†æ
                'key_topics': [],  # TODO: AIæŠ½å‡º
                'summary': f"{title}ã®æ¦‚è¦èª¬æ˜",  # TODO: AIç”Ÿæˆ
                'generated_at': asyncio.get_event_loop().time()
            }
            
            return metadata
            
        except Exception as e:
            logger.error(f"Metadata generation failed: {e}")
            return {}
            
    async def _generate_thumbnail(self, chapter_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ã‚µãƒ ãƒã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ."""
        try:
            title = chapter_data.get('title', '')
            
            # ã‚µãƒ ãƒã‚¤ãƒ«ç”ŸæˆæŒ‡ç¤ºï¼ˆå®Ÿéš›ã®ç”»åƒç”Ÿæˆã¯ MediaWorker ã§è¡Œã†ï¼‰
            thumbnail_request = {
                'type': 'thumbnail',
                'title': title,
                'style': 'modern',
                'color_scheme': 'blue',
                'text_overlay': title,
                'dimensions': {
                    'width': 1200,
                    'height': 630
                },
                'format': 'png'
            }
            
            return thumbnail_request
            
        except Exception as e:
            logger.error(f"Thumbnail data generation failed: {e}")
            return None
            
    def _classify_content_type(self, content: str) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡."""
        content_lower = content.lower()
        
        # æŠ€è¡“ç”¨èªã®æ¤œå‡º
        tech_terms = ['api', 'database', 'server', 'client', 'algorithm', 'code']
        if any(term in content_lower for term in tech_terms) or '```' in content:
            return 'technical'
        elif 'example' in content_lower or 'ä¾‹' in content:
            return 'example'
        elif 'overview' in content_lower or 'æ¦‚è¦' in content:
            return 'overview'
        else:
            return 'general'
            
    def _assess_complexity(self, content: str) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è¤‡é›‘ã•ã‚’è©•ä¾¡."""
        word_count = len(content.split())
        
        if word_count < 50:
            return 'simple'
        elif word_count < 200:
            return 'moderate'
        else:
            return 'complex'
            
    def _extract_key_concepts(self, content: str) -> list[str]:
        """ã‚­ãƒ¼ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’æŠ½å‡º."""
        # TODO: å®Ÿéš›ã®AIåˆ†æã¾ãŸã¯è‡ªç„¶è¨€èªå‡¦ç†
        # ç°¡æ˜“çš„ãªå®Ÿè£…
        keywords = []
        
        # ä¸€èˆ¬çš„ãªæŠ€è¡“ç”¨èªã‚’æ¤œç´¢
        tech_terms = ['API', 'database', 'server', 'client', 'algorithm', 'data', 'system']
        for term in tech_terms:
            if term.lower() in content.lower():
                keywords.append(term)
                
        return keywords[:5]  # æœ€å¤§5å€‹
        
    def _estimate_reading_time(self, content: str) -> int:
        """èª­æ›¸æ™‚é–“ã‚’æ¨å®šï¼ˆåˆ†ï¼‰."""
        word_count = len(content.split())
        # å¹³å‡èª­æ›¸é€Ÿåº¦: 200å˜èª/åˆ†
        return max(1, word_count // 200)
        
    def _recommend_formats(self, content: str) -> list[str]:
        """æ¨å¥¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ±ºå®š."""
        formats = ['article', 'description']
        
        content_type = self._classify_content_type(content)
        
        if content_type == 'technical':
            formats.extend(['script', 'tutorial'])
        elif content_type == 'overview':
            formats.extend(['tweet', 'summary'])
        else:
            formats.append('script')
            
        return formats 